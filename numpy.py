# -*- coding: utf-8 -*-
"""numpy.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Z8L5VIxAodcS9Z6AzFMpAWicLZEjVRmy
"""

import numpy as np
arr1= np.arange(1,21)#start , end , gap of 2
print(arr1)
arr= np.linspace(0,10,3)
print(arr)

arr2 = arr1.reshape((4,5))
print(arr2)
#flatten from 3d to 1d
print(arr2.flatten())

d = np.array([[0,1,2,4],[4,5,6,5],[7,8,9,0]])
print(d)
print("sum= ",np.sum(d))
print("sum of each column= ",np.sum(d,axis=0))
print("sum of each row= ",np.sum(d,axis=1))
print("max val = ",np.max(d))
print("Index of max value (flattened):", np.argmax(d))
print("Min value:", np.min(d))                       # Minimum value
print("Standard Deviation:", np.std(d))
print("sort array=",np.sort(d))
print("Transpose of array=",np.transpose(d))
#find indices where condition is true
idx = np.where(d>5)
print(d[idx])

# Broadcasting allows NumPy to perform operations between arrays of different shapes
a = np.array([1, 2, 3])
b = np.array([[4], [5], [6]])
print(a)
print(b)
print(a+b)
mask =  a>=2
print(mask)
res = np.where(mask, 1, 0)
print(res)

# Random integers from 0 to 100 in 3x3 matrix
rand_ints = np.random.randint(0, 100, size=(3, 3))
print("Random Integers:\n", rand_ints)

# Random values from standard normal distribution (mean=0, std=1)
rand_norm = np.random.randn(2, 4)
print("Random Normal Distribution:\n", rand_norm)

arr1_1 = np.arange(0,99)
arr1_2 = np.ones((3,3))
arr1_3 = np.full((2,4),7)
arr1_4 = np.random.randint(10,51,(5,5))
print(arr1_1)
print(arr1_2)
print(arr1_3)
print(arr1_4)

data = np.array([[10, 20, 30, 40],
                 [50, 60, 70, 80],
                 [90, 100, 110, 120],
                 [130, 140, 150, 160]])
row2_2 = data[0]
print("row2_2:", row2_2)

sub_arr2_4 = data[:2,:2]
print("sub_arr2_4:", sub_arr2_4)

import numpy as np

print("--- Intermediate NumPy Exercise ---")
print("Complete each task by writing the requested NumPy code.")
print("-----------------------------------")

# Task 1: Array Creation Shortcuts
print("\n--- Task 1: Array Creation Shortcuts ---")
# 1.1 Create a 1D array named 'arr1_1' with numbers from 0 to 99 (inclusive) using arange.
# 1.2 Create a 3x3 array named 'arr1_2' filled with ones.
# 1.3 Create a 2x4 array named 'arr1_3' filled with the number 7.
# 1.4 Create a 5x5 array named 'arr1_4' with random integers between 10 and 50 (inclusive).

# Your code for Task 1 here:

arr1_1 = np.arange(0,99)
arr1_2 = np.ones((3,3))
arr1_3 = np.full((2,4),7)
arr1_4 = np.random.randint(10,51,(5,5))
print("arr1_1 (first 10 elements):", arr1_1[:10])
print("arr1_2:\n", arr1_2)
print("arr1_3:\n", arr1_3)
print("arr1_4 (first 2 rows):\n", arr1_4[:2])


# Task 2: Indexing and Slicing with Arrays
print("\n--- Task 2: Indexing and Slicing with Arrays ---")
data = np.array([[10, 20, 30, 40],
                 [50, 60, 70, 80],
                 [90, 100, 110, 120],
                 [130, 140, 150, 160]])

# 2.1 Extract the element at row 2, column 3 (0-indexed). Store it in 'val2_1'.
val2_1 = data[2,3]
print("val2_1:", val2_1)
# 2.2 Extract the first row. Store it in 'row2_2'.
row2_2 = data[0]
print("row2_2:", row2_2)
# 2.3 Extract the last column. Store it in 'col2_3'.
col2_3 = data[:,3]
print("col2_3:", col2_3)
# 2.4 Extract the sub-array consisting of rows 1 and 2, and columns 0 and 1. Store it in 'sub_arr2_4'.
sub_arr2_4 = data[:2,:2]
print("sub_arr2_4:", sub_arr2_4)
# 2.5 Using boolean indexing, select all elements in 'data' that are greater than 100. Store them in 'filtered_elements2_5'.
filtered_elements2_5 = data[data > 100]
print("filtered_elements2_5:", filtered_elements2_5)




# Task 3: Conditional Operations
print("\n--- Task 3: Conditional Operations ---")
arr3_1 = np.random.randint(1, 21, size=(4, 5)) # Random 4x5 array with values 1 to 20

# 3.1 Create a new array 'arr3_2' where elements in 'arr3_1' less than 10 are replaced with 0,
#     and elements greater than or equal to 10 remain unchanged.
# 3.2 Count how many elements in 'arr3_1' are even. Store the count in 'even_count3_3'.

# Your code for Task 3 here:
arr3_2 = np.where(arr3_1 < 10, 0, arr3_1)
even_count3_3 = np.sum(arr3_1 % 2 == 0)
print("arr3_2:", arr3_2)
print("even_count3_3:", even_count3_3)


# Task 4: Aggregation Functions
print("\n--- Task 4: Aggregation Functions ---")
arr4_1 = np.array([[10, 5, 12],
                   [3, 8, 15],
                   [20, 7, 4]])

# 4.1 Calculate the sum of all elements in 'arr4_1'. Store it in 'sum4_1'.
sum4_1 = np.sum(arr4_1)
print("sum4_1:", sum4_1)
# 4.2 Calculate the mean of each column. Store it in 'mean_cols4_2'.
mean_cols4_2 = np.mean(arr4_1, axis=0)
print("mean_cols4_2:", mean_cols4_2)
# 4.3 Find the maximum value in each row. Store it in 'max_rows4_3'.
max_rows4_3 = np.max(arr4_1, axis=1)
print("max_rows4_3:", max_rows4_3)
# 4.4 Calculate the standard deviation of the entire array. Store it in 'std4_4'.
std4_4 = np.std(arr4_1)
print("std4_4:", std4_4)




# Task 5: Reshaping and Flattening
print("\n--- Task 5: Reshaping and Flattening ---")
arr5_1 = np.arange(24) # 1D array from 0 to 23

# 5.1 Reshape 'arr5_1' into a 4x6 2D array. Store it in 'reshaped_arr5_2'.
# 5.2 Reshape 'arr5_1' into a 2x3x4 3D array. Store it in 'reshaped_arr5_3'.
# 5.3 Flatten 'reshaped_arr5_2' back into a 1D array. Store it in 'flattened_arr5_4'.
#     Use both `.ravel()` and `.flatten()` to see if there's a difference (though not visible in output).

# Your code for Task 5 here:
reshaped_arr5_2 = arr5_1.reshape(4,6)
reshaped_arr5_3 = arr5_1.reshape(2,3,4)
flattened_arr5_4 = reshaped_arr5_2.flatten()
flattened_arr5_4 = reshaped_arr5_2.ravel()

# Task 6: Broadcasting
print("\n--- Task 6: Broadcasting ---")
arr6_1 = np.array([[1, 2, 3],
                   [4, 5, 6],
                   [7, 8, 9]])
scalar = 10
vector = np.array([100, 200, 300])

# 6.1 Add the 'scalar' to every element of 'arr6_1'. Store it in 'result6_1'.
# 6.2 Add the 'vector' to each row of 'arr6_1'. Store it in 'result6_2'.

# Your code for Task 6 here:
result6_1 = arr6_1 + scalar
result6_2 = arr6_1 + vector
print("result6_1:\n", result6_1)
print("result6_2:\n", result6_2)


# Task 7: Copying vs. Viewing Arrays
print("\n--- Task 7: Copying vs. Viewing Arrays ---")
original_arr7 = np.array([1, 2, 3, 4, 5])

# 7.1 Create a 'view' of 'original_arr7' named 'view_arr7' by slicing the entire array.
#     Modify the first element of 'view_arr7' to 99.
#     Observe how 'original_arr7' changes.
# 7.2 Create a 'copy' of 'original_arr7' named 'copy_arr7' using `.copy()`.
#     Modify the last element of 'copy_arr7' to 0.
#     Observe how 'original_arr7' remains unchanged.

# Your code for Task 7 here:
view_arr7 = original_arr7[:]
view_arr7[0] = 99
print("original_arr7:", original_arr7)
copy_arr7 = original_arr7.copy()
copy_arr7[-1] = 0
print("original_arr7:", original_arr7)

# Task 8: Stacking and Splitting Arrays
print("\n--- Task 8: Stacking and Splitting Arrays ---")
arr8_a = np.array([[1, 2], [3, 4]])
arr8_b = np.array([[5, 6], [7, 8]])
arr8_c = np.array([[9, 10]])

# 8.1 Vertically stack 'arr8_a' and 'arr8_b'. Store it in 'vstack_arr8_1'.
# 8.2 Horizontally stack 'arr8_a' and 'arr8_b'. Store it in 'hstack_arr8_2'.
# 8.3 Vertically stack 'vstack_arr8_1' and 'arr8_c'. Store it in 'combined_arr8_3'.
# 8.4 Split 'combined_arr8_3' into 3 equal parts (rows). Store them in 'part1', 'part2', 'part3'.

# Your code for Task 8 here:
vstack_arr8_1 = np.vstack((arr8_a, arr8_b))
hstack_arr8_2 = np.hstack((arr8_a, arr8_b))
combined_arr8_3 = np.vstack((vstack_arr8_1, arr8_c))
part1, part2 , part3 = np.array_split(combined_arr8_3,3)
print("part1:\n", part1)
print("part2:\n", part2)
print("part3:\n", part3)


# Task 9: Sorting and Searching
print("\n--- Task 9: Sorting and Searching ---")
arr9_1 = np.array([5, 2, 8, 1, 9, 4, 7, 3, 6])
arr9_2d = np.array([[30, 20, 10],
                    [60, 50, 40],
                    [90, 80, 70]])

# 9.1 Sort 'arr9_1' in ascending order. Store it in 'sorted_arr9_1'.
# 9.2 Sort 'arr9_2d' along columns (i.e., each column sorted independently). Store it in 'sorted_cols9_2'.
# 9.3 Find the indices where the value 9 is present in 'arr9_1'. Store it in 'idx9_3'. (Hint: use np.where)
# 9.4 Find the index of the maximum value in 'arr9_1'. Store it in 'max_idx9_4'.

# Your code for Task 9 here:
sorted_arr9_1 = np.sort(arr9_1)
sorted_cols9_2 = np.sort(arr9_2d, axis=0)
idx9_3 = np.where(arr9_1 == 9)
max_idx9_4 = np.argmax(arr9_1)
print("sorted_arr9_1:", sorted_arr9_1)
print("sorted_cols9_2:\n", sorted_cols9_2)
print("idx9_3:", idx9_3)
print("max_idx9_4:", max_idx9_4)

import pandas as pd
import numpy as np

print("--- Intermediate Pandas Exercise ---")
print("Complete each task by writing the requested Pandas code.")
print("------------------------------------")

# Task 1: Basic Pandas Functions and Converting Arrays to DataFrames
print("\n--- Task 1: Basic Pandas Functions and Converting Arrays to DataFrames ---")
# 1.1 Create a Pandas Series named 's1_1' from a list of numbers [10, 20, 30, 40, 50].
# 1.2 Create a 3x4 NumPy array named 'np_array1_2' with random integers between 1 and 100.
# 1.3 Convert 'np_array1_2' into a Pandas DataFrame named 'df1_3' with columns 'A', 'B', 'C', 'D'.

# Your code for Task 1 here:
s1_1 = pd.Series([10, 20, 30, 40, 50])
np_array1_2 = np.random.randint(1, 101, size=(3, 4))
df1_3 = pd.DataFrame(np_array1_2, columns=['A', 'B', 'C', 'D'])
print(s1_1)
print(df1_3)
print(np_array1_2)


# Task 2: Synthetic Data Generation for Practice
print("\n--- Task 2: Synthetic Data Generation for Practice ---")
# Create a DataFrame named 'df_sales' with 100 rows and the following columns:
# - 'Date': A range of dates from '2023-01-01' to '2023-04-09' (inclusive).
# - 'Region': Randomly chosen from ['East', 'West', 'North', 'South'].
# - 'Product': Randomly chosen from ['Laptop', 'Mouse', 'Keyboard', 'Monitor'].
# - 'Sales': Random integers between 100 and 1000.
# - 'Quantity': Random integers between 1 and 10.
# - Introduce 5 random NaN values in the 'Sales' column and 3 random NaN values in the 'Quantity' column.

# Your code for Task 2 here:
df_sales_dict = {
    'Date': pd.date_range(start='2023-01-01', end='2023-04-09', periods=100),
    'Region': np.random.choice(['East', 'West', 'North', 'South'], size=100),
    'Product': np.random.choice(['Laptop', 'Mouse', 'Keyboard', 'Monitor'], size=100),
    'Sales': np.random.randint(100, 1001, size=100),
    'Quantity': np.random.randint(1, 11, size=100)
}

df_sales = pd.DataFrame(df_sales_dict)

# Introduce NaN values
df_sales.loc[np.random.choice(df_sales.index, 5, replace=False), 'Sales'] = np.nan
df_sales.loc[np.random.choice(df_sales.index, 3, replace=False), 'Quantity'] = np.nan

print(df_sales.head())


# Task 3: Indexing and Slicing in DataFrames
print("Task 3: Indexing and Slicing in DataFrames:")
# Use 'df_sales' from Task 2.
# 3.1 Select only the 'Region' and 'Sales' columns. Store it in 'df3_1'.
# 3.2 Select rows where 'Product' is 'Laptop'. Store it in 'df3_2'.
# 3.3 Select rows where 'Region' is 'East' AND 'Sales' are greater than 500. Store it in 'df3_3'.
# 3.4 Select the 'Sales' value for the first entry where 'Product' is 'Monitor' (use .loc and .iloc). Store it in 'val3_4'.

# Your code for Task 3 here:
df3_1 = df_sales[['Region', 'Sales']]
df3_2 = df_sales[df_sales['Product'] == 'Laptop']
df3_3 = df_sales[(df_sales['Region'] == 'East') & (df_sales['Sales'] > 500)]
val3_4 = df_sales.loc[df_sales['Product'] == 'Monitor', 'Sales'].iloc[0]
print(df3_1.head())
print(df3_2.head())
print(df3_3.head())
print(val3_4)

# Task 4: Data Cleaning (Handling Missing Values)
print("\n--- Task 4: Data Cleaning (Handling Missing Values) ---")
# Use 'df_sales' from Task 2 (which should have NaNs).
# 4.1 Check how many missing values are in each column. Store the result in 'missing_counts4_1'.
# 4.2 Fill missing 'Sales' values with the mean of the 'Sales' column. Store the modified DataFrame in 'df4_2_filled'.
# 4.3 Drop rows that have any missing values in 'df_sales'. Store the result in 'df4_3_dropped'.

# Your code for Task 4 here:
missing_counts4_1 = df_sales.isnull().sum()
df4_2_filled = df_sales.copy()
df4_2_filled['Sales'].fillna(df_sales['Sales'].mean(), inplace=True)
df4_3_dropped = df_sales.dropna()
print(missing_counts4_1)
print(df4_2_filled.head())
print(df4_3_dropped.head())

# Task 5: Data Manipulation (Columns, Sorting, Grouping)
print("\n--- Task 5: Data Manipulation (Columns, Sorting, Grouping) ---")
# Use 'df_sales' (the original one with NaNs)
# 5.1 Create a new column 'Total_Revenue' which is 'Sales' * 'Quantity'.
#     (Be mindful of NaNs, the result should also be NaN where either Sales or Quantity is NaN).
# 5.2 Sort 'df_sales' by 'Date' in ascending order, then by 'Sales' in descending order. Store it in 'df5_2_sorted'.
# 5.3 Group 'df_sales' by 'Region' and calculate the sum of 'Sales' and 'Quantity' for each region.
#     Store the result in 'df5_3_grouped_region'.
# 5.4 Group 'df_sales' by 'Product' and find the average 'Sales' for each product.
#     Store the result in 'df5_4_grouped_product'.

# Your code for Task 5 here:
df_sales['Total_Revenue'] = df_sales['Sales'] * df_sales['Quantity']
print(df_sales[['Sales', 'Quantity', 'Total_Revenue']].head())
df5_2_sorted = df_sales.sort_values(by=['Date', 'Sales'], ascending=[True, False])
print(df5_2_sorted.head())
df5_3_grouped_region = df_sales.groupby('Region')[['Sales', 'Quantity']].sum()
print(df5_3_grouped_region)
df5_4_grouped_product = df_sales.groupby('Product')['Sales'].mean()
print(df5_4_grouped_product)

